[
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "chat_bot",
        "importPath": "Inference",
        "description": "Inference",
        "isExtraImport": true,
        "detail": "Inference",
        "documentation": {}
    },
    {
        "label": "genai",
        "importPath": "google",
        "description": "google",
        "isExtraImport": true,
        "detail": "google",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "prompt",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "prompt = st.chat_input(\"Ketik Pesan\")\n# Memproses input dari user\n# Kode ini dijalankan ketika user mengetik pesan dan menekan Enter\nif prompt:\n    # Memanggil fungsi chat_bot untuk mendapatkan respon dari model\n    # chat_bot(prompt) adalah fungsi dari module Inference.py yang melakukan inferensi\n    # menggunakan model Gemini dan mengembalikan responnya\n    response = chat_bot(prompt)\n    # Menampilkan pesan user di chat\n    with st.chat_message(\"user\"):",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "chat_bot",
        "kind": 2,
        "importPath": "Inference",
        "description": "Inference",
        "peekOfCode": "def chat_bot(prompt) :\n    response = chat.send_message(prompt)\n    return response.text\n#if __name__== \"__main__\":\n    #input_text = input(\"Chat: \")\n    #chat_bot(input_text)\n    #reply=chat_bot(input_text)\n    #print(reply)",
        "detail": "Inference",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "Inference",
        "description": "Inference",
        "peekOfCode": "client = genai.Client(api_key=api_key)\nchat = client.chats.create(model=\"gemini-2.0-flash\")\ndef chat_bot(prompt) :\n    response = chat.send_message(prompt)\n    return response.text\n#if __name__== \"__main__\":\n    #input_text = input(\"Chat: \")\n    #chat_bot(input_text)\n    #reply=chat_bot(input_text)\n    #print(reply)",
        "detail": "Inference",
        "documentation": {}
    },
    {
        "label": "chat",
        "kind": 5,
        "importPath": "Inference",
        "description": "Inference",
        "peekOfCode": "chat = client.chats.create(model=\"gemini-2.0-flash\")\ndef chat_bot(prompt) :\n    response = chat.send_message(prompt)\n    return response.text\n#if __name__== \"__main__\":\n    #input_text = input(\"Chat: \")\n    #chat_bot(input_text)\n    #reply=chat_bot(input_text)\n    #print(reply)",
        "detail": "Inference",
        "documentation": {}
    }
]